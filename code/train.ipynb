{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt, argparse, numpy as np, math, sys, copy\n",
    "from skimage.segmentation import slic, mark_boundaries, felzenszwalb\n",
    "from skimage.util import img_as_float\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "import superpixels as sp\n",
    "import glob\n",
    "import pipeline as pipe\n",
    "import time\n",
    "import superpixels as sp\n",
    "import scipy.stats as sci\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import LoadBatches\n",
    "from Models import Segnet, Unet, VGGSegnet, VGGUnet, FCN8, FCN32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train path and batch size\n",
    "train_images_path = '/media/falreis/falreis1/mestrado/deep_learning/BSDS500/pre_process/images/train/'\n",
    "train_segs_path = '/media/falreis/falreis1/mestrado/deep_learning/BSDS500/pre_process/groundTruth/train/'\n",
    "train_batch_size = 2 #args.batch_size\n",
    "\n",
    "#val path and batch size\n",
    "val_images_path = '/media/falreis/falreis1/mestrado/deep_learning/BSDS500/pre_process/images/val/'\n",
    "val_segs_path = '/media/falreis/falreis1/mestrado/deep_learning/BSDS500/pre_process/groundTruth/val/'\n",
    "val_batch_size = 2 #args.val_batch_size\n",
    "\n",
    "#weights\n",
    "save_weights_path = '/home/falreis/Me/mestrado/ppginf-disciplinas/deep_learning/tp_final/image-segmentation-keras/code/weights/'\n",
    "load_weights = '' #args.load_weights\n",
    "\n",
    "#input height and width\n",
    "input_height = 481 #args.input_height\n",
    "input_width = 481 #args.input_width\n",
    "\n",
    "#classes, validade and epochs\n",
    "n_classes = 2 #args.n_classes\n",
    "validate = 'store_false' #args.validate\n",
    "epochs = 4 # args.epochs\n",
    "\n",
    "#optmizer and model name\n",
    "optimizer_name = 'adam' #args.optimizer_name\n",
    "model_name = 'segnet' #args.model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output shape (None, 3840, 2)\n",
      "Epoch 1/1\n",
      "4800 4800\n",
      "127/128 [============================>.] - ETA: 1s - loss: 0.3723 - acc: 0.80252400 2400\n",
      "128/128 [==============================] - 169s 1s/step - loss: 0.3697 - acc: 0.8040 - val_loss: 0.1143 - val_acc: 0.9680\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 172s 1s/step - loss: 0.0504 - acc: 0.9910 - val_loss: 0.0567 - val_acc: 0.9904\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 185s 1s/step - loss: 0.0303 - acc: 0.9950 - val_loss: 0.0453 - val_acc: 0.9923\n",
      "Epoch 1/1\n",
      "128/128 [==============================] - 190s 1s/step - loss: 0.0509 - acc: 0.9910 - val_loss: 0.0424 - val_acc: 0.9931\n"
     ]
    }
   ],
   "source": [
    "modelFns = { 'segnet':Segnet.Segnet\n",
    "            , 'unet':Unet.Unet\n",
    "            , 'vgg_segnet':VGGSegnet.VGGSegnet\n",
    "            , 'vgg_unet':VGGUnet.VGGUnet\n",
    "            , 'vgg_unet2':VGGUnet.VGGUnet2\n",
    "            , 'fcn8':FCN8.FCN8\n",
    "            , 'fcn32':FCN32.FCN32   \n",
    "}\n",
    "modelFN = modelFns[ model_name ]\n",
    "\n",
    "m = modelFN(n_classes , input_height=input_height, input_width=input_width)\n",
    "m.compile(loss='categorical_crossentropy', optimizer= optimizer_name, metrics=['accuracy'])\n",
    "\n",
    "if len( load_weights ) > 0:\n",
    "    m.load_weights(load_weights)\n",
    "\n",
    "print(\"Model output shape\" ,  m.output_shape)\n",
    "\n",
    "output_height = m.outputHeight\n",
    "output_width = m.outputWidth\n",
    "\n",
    "G  = LoadBatches.imageSegmentationGenerator(train_images_path\n",
    "                                            , train_segs_path\n",
    "                                            , train_batch_size\n",
    "                                            , n_classes\n",
    "                                            , input_height\n",
    "                                            , input_width\n",
    "                                            , output_height\n",
    "                                            , output_width\n",
    ")\n",
    "\n",
    "if validate:\n",
    "    G2  = LoadBatches.imageSegmentationGenerator(val_images_path\n",
    "                                                 , val_segs_path\n",
    "                                                 , val_batch_size\n",
    "                                                 , n_classes\n",
    "                                                 , input_height\n",
    "                                                 , input_width\n",
    "                                                 , output_height\n",
    "                                                 , output_width\n",
    ")\n",
    "\n",
    "if not validate:\n",
    "    for ep in range( epochs ):\n",
    "        m.fit_generator( G , 128  , epochs=1 )\n",
    "        m.save_weights( save_weights_path + \".\" + str( ep ) )\n",
    "        m.save( save_weights_path + \".model.\" + str( ep ) )\n",
    "else:\n",
    "    for ep in range( epochs ):\n",
    "        m.fit_generator( G , 128  , validation_data=G2 , validation_steps=100 ,  epochs=1 )\n",
    "        m.save_weights( save_weights_path + \".\" + str( ep )  )\n",
    "        m.save( save_weights_path + \".model.\" + str( ep ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
