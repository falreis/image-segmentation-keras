\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{cvpr}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}

\def\cvprPaperID{1} % *** Enter the CVPR Paper ID here

\usepackage[breaklinks=true,bookmarks=false]{hyperref}

\cvprfinalcopy % Comment this line and it stop working! :(
\ifcvprfinal\pagestyle{empty}\fi

\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
%\ifcvprfinal\pagestyle{empty}\fi
\setcounter{page}{1}

\graphicspath{ {./images/} } 

\sloppy

%-------------------------------------------------------------------------
%-------------------------------------------------------------------------

\begin{document}

%%%%%%%%% TITLE
\title{\textit{Project Milestone:} Convolutional Neural Network to Image Segmentation}

\author{Felipe Augusto Lima Reis\\
PUC Minas - Pontif\'icia Universidade Cat\'olica de Minas Gerais\\
R. Walter Ianni 255 - Bloco L - Belo Horizonte, MG, Brasil\\
{\tt\small falreis@sga.pucminas.br}
}

\maketitle
%\thispagestyle{empty}

%%%%%%%%% ABSTRACT
\begin{abstract}
   The ABSTRACT is to be in fully-justified italicized text, at the top
   of the left-hand column, below the author and affiliation
   information. Use the word ``Abstract'' as the title, in 12-point
   Times, boldface type, centered relative to the column, initially
   capitalized. The abstract is to be in 10-point, single-spaced type.
   Leave two blank lines after the Abstract, then begin the main text.
   Look at previous CVPR abstracts to get a feel for style and length.
\end{abstract}

%%%%%%%%% BODY TEXT
\section{Introduction} \label{introduction}

Image segmentation refers to the partition of an image into a set of regions to cover it, to represent meaningful areas \cite{DOMINGUEZ}. The goal is to simplify and/or change the representation of an image into something
that is more meaningful and easier to analyze \cite{AHMED_SARMA}.

Segmentation has two main objectives: the first one is to decompose the image into parts for further analysis and the second one is to perform a change of representation \cite{DOMINGUEZ}. Also, segmentation must follow some characteristics to identify regions, as it follows:

\begin{itemize}
 \item Regions of an image segmentation should be uniform and homogeneous with respect to some characteristic, such as gray level, color, or texture \cite{DOMINGUEZ};
 \item Region interiors should be simple and without many small holes \cite{DOMINGUEZ};
 \item Adjacent regions of a segmentation should have significantly different values with respect to the characteristic on which they are uniform \cite{DOMINGUEZ};
 \item Boundaries of each segment should be smooth, not ragged, and should be spatially accurate \cite{DOMINGUEZ}.
\end{itemize}

The future paper will evaluate segmentation methods using Deep Neural Networks and compares with classical methods of segmentation, using the superpixels approach. Also, the paper will evaluate the composition of classical methods with DNN approach, to speed up the training process and become more accurate.

The organization of this paper is as follows. In the next Section we discuss the problem statement. In Section \ref{sec:tech_approach} its explained how the will work and the results we expect. Then in Section \ref{sec:results} we present an some preliminary results.

%-------------------------------------------------------------------------
\section{Problem Statement} \label{sec:prob_statement}

%Describe your problem precisely specifying the dataset to be used, expected results and evaluation

Semantic pixel-wise segmentation is an active topic of research \cite{SEGNET}. Before
 the use of deep neural networks, the best performing methods mostly
 was made using hand engineered features \cite{SEGNET}.

The success of deep convolutional neural networks for object
 classification led researchers to use these technology to learn new capabilities, such as segmentation \cite{SEGNET}. 

In future paper it will evaluate some Deep Neural Network to segmentation, as SEGNET \cite{SEGNET} and U-NET \cite{UNET}, and compare to classical methods, like SLIC (Simple Linear Iterative Clustering) \cite{SLIC} and EGB (Eâ€“cient Graph-Based Image Segmentation) \cite{FELZENSZWALB}. For this, it will be used Berkeley Segmentation Data Set 500 (BSDS500) \cite{BSDS500}.

Berkeley Segmentation Data Set contains 500 natural images and its respectives ground-truths, annotated by humans \cite{BSDS500}. The images are explicitly separated into disjoint train, validation and test subsets \cite{BSDS500}.

To evaluate the quality of the segmentation methods, the results will be evaluated with BSDS500 benchmarking tool, provided with the Dataset \cite{BSDS500}. BSDS500 dataset uses Precision and Recall Method to evaluate the results \cite{BSDS500}.

This work expects better performance of Deep Neural Network when compared with classical methods (SLIC and EGB). The results must be more precise, but with time and space complexity bigger then classical algorithms. 

%-------------------------------------------------------------------------
\section{Technical Approach} \label{sec:tech_approach}

%Describe the methods you intend to apply to solve the given problem

To provide the goals explained in Section \ref{sec:prob_statement}, it  will be used Convolutional Neural Networks provided by the literature. 

%-------------------------------------------------------------------------
\subsection{Deep Neural Networks} \label{ssec:neura_nets}

The project will use two different Neural Networks to provide segmentation, as its follows in the nexts subsections.

%-------------------------------------------------------------------------
\subsubsection{SEGNET} \label{sssec:segnet}

SEGNET is a deep encoder-decoder architecture for multi-class pixelwise segmentation \cite{SEGNET}. The SEGNET architecture consists of a sequence of non-linear processing layers (encoders) and a corresponding set of decoders followed by a pixelwise classifier \cite{SEGNET} \cite{SEGNET_WEBSITE}. Typically, each encoder consists of one or more convolutional layers with batch normalisation and a ReLU non-linearity, followed by non-overlapping maxpooling and sub-sampling \cite{SEGNET} \cite{SEGNET_WEBSITE}. The sparse encoding due to the pooling process is upsampled in the decoder using the maxpooling indices in the encoding sequence \cite{SEGNET} \cite{SEGNET_WEBSITE}. Figure \ref{fig:segnet} presents the representation of SEGNET's architecture.

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.48\textwidth]{segnet.png}
  \caption{SEGNET architecture. \textit{Image adapted from SEGNET project website} \cite{SEGNET_WEBSITE} \cite{SEGNET}}
  \label{fig:segnet}
\end{figure}


%-------------------------------------------------------------------------
\subsubsection{U-NET} \label{sssec:unet}

U-NET is a Convolutional Networks for Biomedical Image Segmentation \cite{UNET} \cite{UNET_WEBSITE}. Although U-NET was developed to biomedical image segmentation, its architecture can be trained to segment other types of image. In this project, we will use U-NET to classify images from BSDS500.

U-NET architecture consists of the repeated application of two 3x3 convolutions (unpadded convolutions), each followed by a rectified linear unit (ReLU) and a 2x2 max pooling operation with stride 2 for downsampling \cite{UNET}. At each downsampling doubles the number of feature channels \cite{UNET}. Every step in the expansive path consists of an upsampling of the feature map followed by a 2x2 convolution, a concatenation with the correspondingly cropped feature map from the contracting path, and two 3x3 convolutions, each followed by a ReLU \cite{UNET}. At the final layer a 1x1 convolution is used to map each 64-component feature vector to the desired number of classes. In total the network has 23 convolutional layers \cite{UNET}. Figure \ref{fig:unet} presents the representation of U-NET's architecture.

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.48\textwidth]{unet.png}
  \caption{U-NET architecture. \textit{Image adapted from U-NET project website} \cite{UNET_WEBSITE} \cite{UNET}}
  \label{fig:unet}
\end{figure}

%-------------------------------------------------------------------------
\subsection{Transfer Learning} \label{ssec:transfer_learning}

Transfer learning is a technique in machine learning that stores knowledge gained while solving one problem, adapt and apply it to a different but related problem. As the grow of neural networks usage, it becomes reasonable to seek out methods that avoid ``reinventing the wheel'', and
 instead are able to build on previously trained networks' results \cite{PRATT} \cite{WEISS2016}.

In this work it expected to use transfer learning to speed up the training process. For that, it will be used a pretrained VGGNET (Very Deep Convolutional Networks for Large-Scale Image Recognition) \cite{VGGNET}.


%-------------------------------------------------------------------------
\subsection{Data Augmentation} \label{ssec:data_augmentation}

% TODO Explain Data Augmentation

Once BSDS500 contains only 200 images for training and 100 images for validation, the Neural Network may not learn enough information from the dataset. Then, it's necessary to add some images for training, based on the training and validation set.

To provide data augmentation, the images and the ground-truth will be rotated 12 times, 30 degrees each. Also, the images will be flipped and rotated 12 times either. Then, each image will transform into 24 possible images. Then, 200 images for training will become 4800 training images. The number of images is not too big, but can help the DNN predict with more accuracy.

%-------------------------------------------------------------------------
\section{Preliminary Results} \label{sec:results}

%State and evaluate your results upto the milestone

%-------------------------------------------------------------------------

{\small
\bibliographystyle{ieee}
\bibliography{egbib}
}

\end{document}
